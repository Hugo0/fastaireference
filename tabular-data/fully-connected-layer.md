---
description: The simplest of NN's
---

# Fully connected layer

A fully connected layer \(FCL\) is one of the earliest forms of neural networks, mostly used to classify inputs. Such a layer is characterized by having a connection \(a weight\) to \*all\* of the nodes in the previous and consequent layer.

![An example fully connected layer](../.gitbook/assets/image%20%2813%29.png)

Fully connected layers are useful; in fact, a neural network consisting of one input layer, one output layer, and one FCL in the middle [can theoretically replicate _any function_](https://en.wikipedia.org/wiki/Universal_approximation_theorem). The problem of course is that the number of nodes blows up and makes a one-layer network computationally infeasible.



